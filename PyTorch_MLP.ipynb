{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "PyTorch_MLP.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3XLDg9PfhRx",
        "colab_type": "text"
      },
      "source": [
        "# PyTorch code for a Multilayer Perceptron\n",
        "\n",
        "In this section we will go through the code for a multilayer perceptron in PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MPz1BAo8Y257"
      },
      "source": [
        "First of all we set up the required imports and set up the device used for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cSa1m_ulY257",
        "outputId": "4c6e7bf3-4512-47e7-90f7-4a9488e29ba8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import division, print_function, absolute_import\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sklearn.metrics as metrics\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "device = torch.device('cuda')\n",
        "      \n",
        "print('PyTorch version:', torch.__version__, ' Device:', device)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch version: 1.5.0+cu101  Device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IcMouaN4Y26G"
      },
      "source": [
        "Here are the relevant network parameters and graph input for context."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3Uq_T26cY26H",
        "colab": {}
      },
      "source": [
        "# Hyper-Parameters\n",
        "learning_rate = 0.001 # Initial learning rate\n",
        "training_epochs = 15 # Number of epochs to train\n",
        "batch_size = 100 # Number of images per batch\n",
        "display_step = 1 # How often to output model metrics during training\n",
        "\n",
        "# Network Parameters\n",
        "n_hidden_1 = 256 # 1st layer number of neurons\n",
        "n_hidden_2 = 256 # 2nd layer number of neurons\n",
        "n_input = 784 # MNIST data input (img shape: 28*28)\n",
        "n_classes = 10 # MNIST total classes (0-9 digits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPfSHnHZfq6Y",
        "colab_type": "text"
      },
      "source": [
        "Here, we load the MNIST dataset from the torchvision library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IhTUw_JcY26S",
        "colab": {}
      },
      "source": [
        "# The dataset\n",
        "train_dataset = datasets.MNIST('./data', \n",
        "                               train=True, \n",
        "                               download=True, \n",
        "                               transform=transforms.ToTensor())\n",
        "\n",
        "test_dataset = datasets.MNIST('./data', \n",
        "                                    train=False, \n",
        "                                    transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                                batch_size=batch_size, \n",
        "                                                shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9XhIOarEY26X"
      },
      "source": [
        "### Model Creation\n",
        "Here, we create a ‘multi-layer’ model as there is more than one hidden layer, as below we define `fc_1` and `fc_2`.\n",
        "\n",
        "The MLP definition below does two things:\n",
        "\n",
        "1. It defines the model in Multilayer_Perceptron().\n",
        "2. It initialises and assigns values to each layer of the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ovgOoeolY26Y",
        "colab": {}
      },
      "source": [
        "class Multilayer_Perceptron(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Multilayer_Perceptron, self).__init__()\n",
        "\n",
        "        # Hidden fully connected layers with 256 neurons\n",
        "        self.fc1 = nn.Linear(n_input, n_hidden_1)\n",
        "        self.fc2 = nn.Linear(n_hidden_1, n_hidden_2)\n",
        "        self.out = nn.Linear(n_hidden_2, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return F.log_softmax(self.out(x), dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rfp_GvdGY26d"
      },
      "source": [
        "### Define loss and optimizer\n",
        "\n",
        "In the following snippet we define our model, loss operation, optimiser."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uHtF7rUtY26d",
        "colab": {}
      },
      "source": [
        "model = Multilayer_Perceptron().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AlrQvH-5Y26h"
      },
      "source": [
        "### Train and evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fTw-xHrgY26i",
        "outputId": "c988da5e-47b0-48ea-e4a8-323ed83ba400",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "# Set model to training mode\n",
        "model.train()\n",
        "\n",
        "# training loop\n",
        "for epoch in range(training_epochs):\n",
        "# Loop over each batch from the training set\n",
        "    for batch_idx, (img, lbl) in enumerate(train_loader):\n",
        "        # Copy image data to GPU if available\n",
        "        img = img.to(device)\n",
        "        lbl = lbl.to(device)\n",
        "\n",
        "        # Zero gradient buffers\n",
        "        optimizer.zero_grad() \n",
        "        \n",
        "        # Pass image data through the network\n",
        "        output = model(img)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(output, lbl)\n",
        "\n",
        "        # Backpropagate\n",
        "        loss.backward()\n",
        "        \n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "    \n",
        "    if epoch % display_step == 0:\n",
        "        print(\"Epoch:\", '%04d' % (epoch+1), \"Loss = {:.9f}\".format(loss.item()))\n",
        "\n",
        "print(\"Optimization Finished!\")\n",
        "\n",
        "# set model to evaluation mode\n",
        "\n",
        "model.eval()\n",
        "\n",
        "correct = 0\n",
        "\n",
        "for test_img, test_lbl in test_loader:\n",
        "\n",
        "    test_img = test_img.to(device)\n",
        "    test_lbl = test_lbl.to(device)\n",
        "\n",
        "    output = model(test_img)\n",
        "\n",
        "    _, pred = torch.max(output, dim=1)\n",
        "\n",
        "    correct += pred.eq(test_lbl).cpu().sum()\n",
        "\n",
        "accuracy = 100. * correct.to(torch.float32) / len(test_loader.dataset)\n",
        "\n",
        "print(\"\\nAccuracy:\", accuracy.item())\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 Loss = 0.161436126\n",
            "Epoch: 0002 Loss = 0.019867852\n",
            "Epoch: 0003 Loss = 0.165738449\n",
            "Epoch: 0004 Loss = 0.008798224\n",
            "Epoch: 0005 Loss = 0.058917552\n",
            "Epoch: 0006 Loss = 0.049724430\n",
            "Epoch: 0007 Loss = 0.025562609\n",
            "Epoch: 0008 Loss = 0.007177592\n",
            "Epoch: 0009 Loss = 0.004394918\n",
            "Epoch: 0010 Loss = 0.024284890\n",
            "Epoch: 0011 Loss = 0.000169355\n",
            "Epoch: 0012 Loss = 0.031441476\n",
            "Epoch: 0013 Loss = 0.002443283\n",
            "Epoch: 0014 Loss = 0.000446099\n",
            "Epoch: 0015 Loss = 0.000870296\n",
            "Optimization Finished!\n",
            "\n",
            "Accuracy: 98.1500015258789\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
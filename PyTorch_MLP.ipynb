{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PyTorch code for a Multilayer Perceptron\n",
    "\n",
    "In this section we will go through the code for a multilayer perceptron in PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we set up the required imports and set up the device used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../scratch/train-images-idx3-ubyte.gz\n",
      "Extracting ../scratch/train-labels-idx1-ubyte.gz\n",
      "Extracting ../scratch/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../scratch/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print('PyTorch version:', torch.__version__, ' Device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the relevant network parameters and graph input for context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-Parameters\n",
    "learning_rate = 0.001 # Initial learning rate\n",
    "training_epochs = 5 # Number of epochs to train\n",
    "batch_size = 100 # Number of images per batch\n",
    "display_step = 1 # How often to output model metrics during training\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of neurons\n",
    "n_hidden_2 = 256 # 2nd layer number of neurons\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Here, we load the MNIST dataset from the torchvision library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset\n",
    "train_dataset = datasets.MNIST('./data', \n",
    "                               train=True, \n",
    "                               download=True, \n",
    "                               transform=transforms.ToTensor())\n",
    "\n",
    "test_dataset = datasets.MNIST('./data', \n",
    "                                    train=False, \n",
    "                                    transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                                batch_size=batch_size, \n",
    "                                                shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation\n",
    "Here, we create a ‘multi-layer’ model as there is more than one hidden layer, as below we define `fc_1` and `fc_2`.\n",
    "\n",
    "The MLP definition below does two things:\n",
    "\n",
    "1. It defines the model in Multilayer_Perceptron().\n",
    "2. It initialises and assigns values to each layer of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multilayer_Perceptron(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Multilayer_Perceptron, self).__init__()\n",
    "\n",
    "        # Hidden fully connected layer with 256 neurons\n",
    "        self.fc1 = nn.Linear(n_input, n_hidden_1)\n",
    "        self.fc2 = nn.Linear(n_hidden_1, n_hidden_2)\n",
    "        self.out = nn.Linear(n_hidden_2, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.log_softmax(self.out(x), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss and optimizer\n",
    "\n",
    "In the following snippet we define our model, loss operation, optimiser. PyTorch will take care of all initialisation for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Multilayer_Perceptron().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost=287.250201395\n",
      "Epoch: 0002 cost=91.597096405\n",
      "Epoch: 0003 cost=68.684905194\n",
      "Epoch: 0004 cost=55.829017655\n",
      "Epoch: 0005 cost=47.115250719\n",
      "Epoch: 0006 cost=41.359397067\n",
      "Epoch: 0007 cost=37.130086868\n",
      "Epoch: 0008 cost=33.303088518\n",
      "Epoch: 0009 cost=30.589550092\n",
      "Epoch: 0010 cost=28.341824516\n",
      "Epoch: 0011 cost=26.929923002\n",
      "Epoch: 0012 cost=24.618215298\n",
      "Epoch: 0013 cost=23.411146597\n",
      "Epoch: 0014 cost=22.941275415\n",
      "Epoch: 0015 cost=21.737917544\n",
      "Optimization Finished!\n",
      "Accuracy: 0.8837\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb884807710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set model to training mode\n",
    "model.train()\n",
    "\n",
    "# training loop\n",
    "for epoch in range(training_epochs):\n",
    "# Loop over each batch from the training set\n",
    "    for batch_idx, (img, lbl) in enumerate(train_loader):\n",
    "        # Copy image data to GPU if available\n",
    "        img = img.to(device)\n",
    "        lbl = lbl.to(device)\n",
    "\n",
    "        # Zero gradient buffers\n",
    "        optimizer.zero_grad() \n",
    "        \n",
    "        # Pass image data through the network\n",
    "        output = model(img)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(output, lbl)\n",
    "\n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "    \n",
    "    if epoch % display_step == 0:\n",
    "        print(\"Epoch:\", '%04d' % (epoch+1), \"Loss = {:.9f}\".format(loss.item()))\n",
    "\n",
    "print(\"Optimization Finished!\")\n",
    "\n",
    "# et model to evaluation mode\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for data, target in test_loader:\n",
    "\n",
    "    data = data.to(device)\n",
    "    target = target.to(device)\n",
    "\n",
    "    output = model(data)\n",
    "\n",
    "    _, pred = torch.max(output, dim=1)\n",
    "\n",
    "    correct += pred.eq(target).cpu().sum()\n",
    "\n",
    "accuracy = 100. * correct.to(torch.float32) / len(test_loader.dataset)\n",
    "\n",
    "print(\"Accuracy:\", accuracy.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup tensorboard for Google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import subprocess\n",
    "\n",
    "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "!unzip -o ngrok-stable-linux-amd64.zip\n",
    "\n",
    "LOG_DIR = os.getcwd()\n",
    "get_ipython().system_raw(\n",
    "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
    "    .format(LOG_DIR)\n",
    ")\n",
    "\n",
    "\n",
    "proc = subprocess.Popen(['%s/ngrok' % os.getcwd() , 'http', '6006'])\n",
    "print (\"start ngrok with pid %s\" % proc.pid)\n",
    "\n",
    "time.sleep(3)\n",
    "try:\n",
    "    ! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "        \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "#proc.kill()\n",
    "#! rm -rf *"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_lAoorImY25w"
   },
   "source": [
    "# PyTorch code for a Multilayer Perceptron\n",
    "\n",
    "In this section we will go through the code for a multilayer perceptron in PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MPz1BAo8Y257"
   },
   "source": [
    "First of all we set up the required imports and set up the device used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cSa1m_ulY257",
    "outputId": "515e20bd-d82c-4e2b-8f98-c7a8919cb620"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.5.0+cu101  Device: cuda\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "      \n",
    "print('PyTorch version:', torch.__version__, ' Device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IcMouaN4Y26G"
   },
   "source": [
    "Here are the relevant network parameters and graph input for context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Uq_T26cY26H"
   },
   "outputs": [],
   "source": [
    "# Hyper-Parameters\n",
    "learning_rate = 0.001 # Initial learning rate\n",
    "training_epochs = 15 # Number of epochs to train\n",
    "batch_size = 100 # Number of images per batch\n",
    "display_step = 1 # How often to output model metrics during training\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of neurons\n",
    "n_hidden_2 = 256 # 2nd layer number of neurons\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fM_nIQ4OY26N"
   },
   "source": [
    "Here, we load the MNIST dataset from the torchvision library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IhTUw_JcY26S"
   },
   "outputs": [],
   "source": [
    "# The dataset\n",
    "train_dataset = datasets.MNIST('./data', \n",
    "                               train=True, \n",
    "                               download=True, \n",
    "                               transform=transforms.ToTensor())\n",
    "\n",
    "test_dataset = datasets.MNIST('./data', \n",
    "                                    train=False, \n",
    "                                    transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                                batch_size=batch_size, \n",
    "                                                shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9XhIOarEY26X"
   },
   "source": [
    "### Model Creation\n",
    "Here, we create a ‘multi-layer’ model as there is more than one hidden layer, as below we define `fc_1` and `fc_2`.\n",
    "\n",
    "The MLP definition below does two things:\n",
    "\n",
    "1. It defines the model in Multilayer_Perceptron().\n",
    "2. It initialises and assigns values to each layer of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ovgOoeolY26Y"
   },
   "outputs": [],
   "source": [
    "class Multilayer_Perceptron(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Multilayer_Perceptron, self).__init__()\n",
    "\n",
    "        # Hidden fully connected layers with 256 neurons\n",
    "        self.fc1 = nn.Linear(n_input, n_hidden_1)\n",
    "        self.fc2 = nn.Linear(n_hidden_1, n_hidden_2)\n",
    "        self.out = nn.Linear(n_hidden_2, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.log_softmax(self.out(x), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rfp_GvdGY26d"
   },
   "source": [
    "### Define loss and optimizer\n",
    "\n",
    "In the following snippet we define our model, loss operation, optimiser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uHtF7rUtY26d"
   },
   "outputs": [],
   "source": [
    "model = Multilayer_Perceptron().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AlrQvH-5Y26h"
   },
   "source": [
    "### Train and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "colab_type": "code",
    "id": "fTw-xHrgY26i",
    "outputId": "cc89de35-3aea-40dd-f236-78a92233a8fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 Loss = 0.002095348\n",
      "Epoch: 0002 Loss = 0.010344102\n",
      "Epoch: 0003 Loss = 0.013237882\n",
      "Epoch: 0004 Loss = 0.000267775\n",
      "Epoch: 0005 Loss = 0.009599728\n",
      "Epoch: 0006 Loss = 0.016471514\n",
      "Epoch: 0007 Loss = 0.000801177\n",
      "Epoch: 0008 Loss = 0.001382481\n",
      "Epoch: 0009 Loss = 0.010902218\n",
      "Epoch: 0010 Loss = 0.000892415\n",
      "Epoch: 0011 Loss = 0.002392501\n",
      "Epoch: 0012 Loss = 0.011192990\n",
      "Epoch: 0013 Loss = 0.000859393\n",
      "Epoch: 0014 Loss = 0.000613048\n",
      "Epoch: 0015 Loss = 0.037429959\n",
      "Optimization Finished!\n",
      "\n",
      "Accuracy: 98.01000213623047\n"
     ]
    }
   ],
   "source": [
    "# Set model to training mode\n",
    "model.train()\n",
    "\n",
    "# training loop\n",
    "for epoch in range(training_epochs):\n",
    "# Loop over each batch from the training set\n",
    "    for batch_idx, (img, lbl) in enumerate(train_loader):\n",
    "        # Copy image data to GPU if available\n",
    "        img = img.to(device)\n",
    "        lbl = lbl.to(device)\n",
    "\n",
    "        # Zero gradient buffers\n",
    "        optimizer.zero_grad() \n",
    "        \n",
    "        # Pass image data through the network\n",
    "        output = model(img)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(output, lbl)\n",
    "\n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "    \n",
    "    if epoch % display_step == 0:\n",
    "        print(\"Epoch:\", '%04d' % (epoch+1), \"Loss = {:.9f}\".format(loss.item()))\n",
    "\n",
    "print(\"Optimization Finished!\")\n",
    "\n",
    "# set model to evaluation mode\n",
    "\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "\n",
    "for test_img, test_lbl in test_loader:\n",
    "\n",
    "    test_img = test_img.to(device)\n",
    "    test_lbl = test_lbl.to(device)\n",
    "\n",
    "    output = model(test_img)\n",
    "\n",
    "    _, pred = torch.max(output, dim=1)\n",
    "\n",
    "    correct += pred.eq(test_lbl).cpu().sum()\n",
    "\n",
    "accuracy = 100. * correct.to(torch.float32) / len(test_loader.dataset)\n",
    "\n",
    "print(\"\\nAccuracy:\", accuracy.item())\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "PyTorch_MLP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
